{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from scipy.fft import fft, fftshift, fftfreq\n",
    "from scipy.signal.windows import hamming\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from math import log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 8),  # Change figure size\n",
    "    'lines.linewidth': 2,      # Change line width\n",
    "    'axes.labelsize': 38,      # Change label font size\n",
    "    'axes.titlesize': 40,      # Change title font size\n",
    "    'legend.fontsize': 30,     # Change legend font size\n",
    "    'xtick.labelsize': 36,     # Change x-axis tick font size\n",
    "    'ytick.labelsize': 36,      # Change y-axis tick font size\n",
    "    'figure.autolayout': True  # Automatically adjust layout to fit labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cross_correlation(P1, P2, max_lag):\n",
    "    if len(P1) != len(P2):\n",
    "        raise ValueError(\"P1 and P2 must have the same length\")\n",
    "    \n",
    "    n = len(P1)\n",
    "    mean_P1 = np.mean(P1)\n",
    "    mean_P2 = np.mean(P2)\n",
    "\n",
    "    lags = np.arange(-max_lag, max_lag + 1)\n",
    "    C = np.zeros(len(lags))\n",
    "\n",
    "    for i, Δt in enumerate(lags):\n",
    "        if Δt >= 0:\n",
    "            num = np.mean((P1[:n-Δt] - mean_P1) * (P2[Δt:] - mean_P2))\n",
    "        else:\n",
    "            num = np.mean((P1[-Δt:] - mean_P1) * (P2[:n+Δt] - mean_P2))\n",
    "        denom = np.sqrt(np.mean((P1 - mean_P1)**2) * np.mean((P2 - mean_P2)**2))\n",
    "        C[i] = num / denom\n",
    "\n",
    "    return lags, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_correlation_previous(dataset1, dataset2, delta_t, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Compute sliding window correlation between two signals with a delay applied to dataset1.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset1: np.array, the slave (lagging) dataset\n",
    "    - dataset2: np.array, the master (leading) dataset\n",
    "    - delta_t: int, the delay (in samples)\n",
    "    - window_size: int, number of samples in each window\n",
    "    - step_size: int, step size for the sliding window\n",
    "\n",
    "    Returns:\n",
    "    - indices: np.array of int, window start indices\n",
    "    - correlations: np.array of float, absolute correlation values per window\n",
    "    \"\"\"\n",
    "    dataset1 = np.asarray(dataset1)\n",
    "    dataset2 = np.asarray(dataset2)\n",
    "\n",
    "    n = len(dataset1)\n",
    "    start_indices = np.arange(0, n - window_size - delta_t + 1, step_size)\n",
    "    correlations = np.empty(len(start_indices))\n",
    "\n",
    "    for idx, i in enumerate(start_indices):\n",
    "        window1 = dataset1[i : i + window_size]\n",
    "        window2 = dataset2[i + delta_t : i + delta_t + window_size]\n",
    "        correlations[idx] = abs(np.corrcoef(window1, window2)[0, 1])\n",
    "\n",
    "    return start_indices, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50a6c9",
   "metadata": {},
   "source": [
    "# Temporal trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a678370",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δf_list = np.arange(-30,31)\n",
    "Δf_list = np.round(Δf_list, 1)  # Round to 2 decimal place    \n",
    "\n",
    "for Δf in Δf_list:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    file_path = os.path.join(rf\"C:\\Users\\magic\\OneDrive\\Desktop\\Programas\\Julia_programs\\beca_jae_julia\\Lang-kobayashi\\four_lasers_simulations\\results\\two_lasers\\results_laser_1_vs_laser_1_same_delay\\laser_simulation_Δf_{Δf}_GHz_laser_1_laser_1_lab_same_delay_new_k_0.15.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Clean and convert Julia complex strings to Python complex\n",
    "    def parse_julia_complex(s):\n",
    "        try:\n",
    "            s = s.replace(\"im\", \"j\").replace(\" \", \"\")\n",
    "            return complex(s)\n",
    "        except:\n",
    "            return np.nan  # or raise if you want to catch malformed ones\n",
    "\n",
    "\n",
    "    # Apply to each column\n",
    "    t = df[\"time\"].values\n",
    "    E1 = np.array([parse_julia_complex(x) for x in df[\"E1\"]])\n",
    "    E2 = np.array([parse_julia_complex(x) for x in df[\"E2\"]])\n",
    "\n",
    "    # Compute intensities\n",
    "    S1 = np.abs(E1)**2\n",
    "    S2 = np.abs(E2)**2\n",
    "\n",
    "    index_steady = np.argmax(t > 1900e-9) -1\n",
    "    t_steady = t[index_steady:] * 10**(9)\n",
    "    S1_steady = S1[index_steady:]\n",
    "    S2_steady = S2[index_steady:] \n",
    "\n",
    "    index_steady_2 = np.argmax(t > 1990e-9) -1\n",
    "    t_steady_2 = t[index_steady_2:] * 10**(9)\n",
    "    S1_steady_2 = S1[index_steady_2:]\n",
    "    S2_steady_2 = S2[index_steady_2:]\n",
    "\n",
    "    index_transient = np.argmax(t >= 30e-9) - 1\n",
    "    t_transient = t[:index_transient] * 10**(9)\n",
    "    S1_transient = S1[:index_transient] \n",
    "    S2_transient = S2[:index_transient] \n",
    "\n",
    "    t = t * 10**(9)\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(t, S1, label=\"$S_1$\")\n",
    "    plt.plot(t, S2, label=\"$S_2$\")\n",
    "    plt.xlabel(\"t (ns)\")\n",
    "    plt.ylabel(\"S\")\n",
    "    plt.title(rf\"{Δf}\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"trace_laser_1_vs_laser_1_diff_delay_noise_k_0.15_deltaf_0_GHz.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δf_list = np.arange(-10,0,0.5)\n",
    "Δf_list = np.round(Δf_list, 1)  # Round to 2 decimal place    \n",
    "\n",
    "for Δf in Δf_list:\n",
    "    # Load the CSV file into a DataFrame\n",
    "    file_path = os.path.join(rf\"/home/adam/vscode/python/Infolante/traces/results_4_laser_new_params_larger_wait_increased_alpha_1/4_lasers_simulation_Δf_{Δf}_RK4_no_noise_new_params_larger_wait.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Clean and convert Julia complex strings to Python complex\n",
    "    def parse_julia_complex(s):\n",
    "        try:\n",
    "            s = s.replace(\"im\", \"j\").replace(\" \", \"\")\n",
    "            return complex(s)\n",
    "        except:\n",
    "            return np.nan  # or raise if you want to catch malformed ones\n",
    "\n",
    "\n",
    "    # Apply to each column\n",
    "    t = df[\"time\"].values\n",
    "    E1 = np.array([parse_julia_complex(x) for x in df[\"E1\"]])\n",
    "    E2 = np.array([parse_julia_complex(x) for x in df[\"E2\"]])\n",
    "    E3 = np.array([parse_julia_complex(x) for x in df[\"E3\"]])\n",
    "    E4 = np.array([parse_julia_complex(x) for x in df[\"E4\"]])\n",
    "\n",
    "    # Compute intensities\n",
    "    S1 = np.abs(E1)**2\n",
    "    S2 = np.abs(E2)**2\n",
    "    S3 = np.abs(E3)**2\n",
    "    S4 = np.abs(E4)**2\n",
    "\n",
    "\n",
    "    t = t * 10**(9)\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(t, S1, label=\"$S_1$\")\n",
    "    plt.plot(t, S2, label=\"$S_2$\")\n",
    "    plt.plot(t, S3, label=\"$S_3$\")\n",
    "    plt.plot(t, S4, label=\"$S_4$\")\n",
    "    plt.xlabel(\"t (ns)\")\n",
    "    plt.ylabel(\"S\")\n",
    "    plt.title(rf\"{Δf}\")\n",
    "    #plt.legend()\n",
    "    #plt.savefig(rf\"trace_laser_1_vs_laser_1_diff_delay_noise_k_0.15_deltaf_{Δf}_GHz.png\")\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ca71c",
   "metadata": {},
   "source": [
    "# RHF and optical spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02b660",
   "metadata": {},
   "source": [
    "Here we estimate the relaxation frequency $\\nu_{R}$ of the lasers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0489480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_function_delay_laser():\n",
    "    # === Load CSV ===lasers_simulations\\4_la\n",
    "    \n",
    "    file_path = os.path.join(rf\"D:\\four_lasers\\4_lasers_simulation_Δf_0_all_k_0.1_freq_missmatch_laser_1_k_0.15_solitary_laser.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # === Time vector and steady-state cut ===\n",
    "    t = df[\"time\"].values\n",
    "    index_steady = np.argmax(t > 10e-9)\n",
    "    t = t[index_steady:]\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    # === Complex conversion helper ===\n",
    "    def parse_julia_complex(x):\n",
    "        return complex(x.replace(\"im\", \"j\").replace(\" \", \"\"))\n",
    "\n",
    "    # === Parse and slice complex fields ===\n",
    "    E_fields = {}\n",
    "    for i in range(1, 5):\n",
    "        col = f\"E{i}\"\n",
    "        E_fields[col] = np.array([parse_julia_complex(val) for val in df[col]])[index_steady:]\n",
    "\n",
    "    # === Apply Hamming window ===\n",
    "    window = hamming(len(t))\n",
    "\n",
    "    # === FFT of intensities (|E|^2) ===\n",
    "    freqs = fftshift(fftfreq(len(t), dt)) / 1e9  # GHz\n",
    "    valid = freqs > 0.01\n",
    "\n",
    "    plt.figure()\n",
    "    for i in range(1, 5):\n",
    "        E = np.abs(E_fields[f\"E{i}\"])**2\n",
    "        spectrum = np.abs(fftshift(fft(E * window)))\n",
    "        spectrum = 10*np.log10(spectrum)\n",
    "        plt.plot(freqs[valid], spectrum[valid], label=f\"Laser {i}\")\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel(r\"$\\nu$ (GHz)\")\n",
    "    plt.ylabel(r\"Intensity (dB)\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(os.path.join(os.getcwd(), \"RFS_4_lasers_Δf_-7.6_GHz_noise.png\"))\n",
    "\n",
    "    # === Zoomed view of above ===\n",
    "    plt.figure()\n",
    "    for i in range(1, 5):\n",
    "        E = np.abs(E_fields[f\"E{i}\"])**2\n",
    "        spectrum = np.abs(fftshift(fft(E * window)))\n",
    "        spectrum = 10*np.log10(spectrum)\n",
    "        plt.plot(freqs[valid], spectrum[valid], label=f\"Laser {i}\")\n",
    "    #plt.yscale('log')\n",
    "    plt.xlim([0, 20])\n",
    "    plt.xlabel(r\"$\\nu$ (GHz)\")\n",
    "    plt.ylabel(r\"Intensity (dB)\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(os.path.join(os.getcwd(), \"RFS_4_lasers_zoom_Δf_-7.6_GHz_noise.png\"))\n",
    "\n",
    "    # === FFT of complex fields (optical spectra) ===\n",
    "    plt.figure()\n",
    "    for i in range(1, 5):\n",
    "        E_complex = E_fields[f\"E{i}\"]\n",
    "        spectrum_c = np.abs(fftshift(fft(E_complex * window)))\n",
    "        db_spectrum = 20 * np.log10(spectrum_c)\n",
    "        plt.plot(freqs, db_spectrum, label=f\"Laser {i}\")\n",
    "    plt.xlim([-20, 20])\n",
    "    plt.xlabel(r\"$\\nu$ (GHz)\")\n",
    "    plt.ylabel(r\"Intensity (dB)\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(os.path.join(os.getcwd(), \"optical_spectra_4_lasers_Δf_-7.6_GHz_noise.png\"))\n",
    "\n",
    "    \n",
    "    relaxation_freqs = {}\n",
    "    relaxation_errors = {}\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        E = np.abs(E_fields[f\"E{i}\"])**2\n",
    "        spectrum = np.abs(fftshift(fft(E * window)))\n",
    "        spectrum = 10*np.log(spectrum)\n",
    "\n",
    "        # Mask\n",
    "        spectrum_valid = spectrum[valid]\n",
    "        freqs_valid = freqs[valid]\n",
    "\n",
    "        # Find peaks\n",
    "        peaks, _ = find_peaks(spectrum_valid, height=-70)  # Only consider visible peaks\n",
    "\n",
    "        if peaks.size > 0:\n",
    "            peak_idx = peaks[np.argmax(spectrum_valid[peaks])]\n",
    "            peak_freq = freqs_valid[peak_idx]\n",
    "\n",
    "            # Estimate error using FWHM (crude Gaussian-like assumption)\n",
    "            half_max = spectrum_valid[peak_idx] - 3  # ~3 dB down from peak\n",
    "            # Interpolate curve around peak to find where it drops to half max\n",
    "            interp_func = interp1d(freqs_valid, spectrum_valid, kind='linear')\n",
    "            freqs_fine = np.linspace(freqs_valid[0], freqs_valid[-1], 10000)\n",
    "            spectrum_fine = interp_func(freqs_fine)\n",
    "            above_half = freqs_fine[spectrum_fine >= half_max]\n",
    "\n",
    "            if len(above_half) >= 2:\n",
    "                fwhm = above_half[-1] - above_half[0]\n",
    "                error = fwhm / 2  # crude ± estimate\n",
    "            else:\n",
    "                error = None\n",
    "\n",
    "            relaxation_freqs[i] = peak_freq\n",
    "            relaxation_errors[i] = error\n",
    "\n",
    "            print(f\"{i}: Relaxation Frequency = {peak_freq}±{error} GHz\")\n",
    "\n",
    "\n",
    "\n",
    "plot_function_delay_laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_function_delay_laser():\n",
    "    # === Load CSV ===lasers_simulations\\4_la\n",
    "    Δf_list = np.arange(-10,1,0.5)\n",
    "    Δf_list = np.round(Δf_list, 1)  # Round to 2 decimal place    \n",
    "\n",
    "    for Δf in Δf_list:\n",
    "        # Load the CSV file into a DataFrame\n",
    "        file_path = os.path.join(rf\"/home/adam/vscode/python/Infolante/traces/results_4_lasers_new_params_larger_wait/4_lasers_simulation_Δf_{Δf}_RK4_no_noise_new_params_larger_wait.csv\")\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # === Time vector and steady-state cut ===\n",
    "        t = df[\"time\"].values\n",
    "        index_steady = np.argmax(t > 19600e-9)\n",
    "        t = t[index_steady:]\n",
    "        dt = t[1] - t[0]\n",
    "\n",
    "        # === Complex conversion helper ===\n",
    "        def parse_julia_complex(x):\n",
    "            return complex(x.replace(\"im\", \"j\").replace(\" \", \"\"))\n",
    "\n",
    "        # === Parse and slice complex fields ===\n",
    "        E_fields = {}\n",
    "        for i in range(1, 3):\n",
    "            col = f\"E{i}\"\n",
    "            E_fields[col] = np.array([parse_julia_complex(val) for val in df[col]])[index_steady:]\n",
    "\n",
    "        # === Apply Hamming window ===\n",
    "        window = hamming(len(t))\n",
    "\n",
    "    # === FFT of intensities (|E|^2) ===\n",
    "        freqs = fftshift(fftfreq(len(t), dt)) / 1e9  # GHz\n",
    "        valid = freqs > 0.01\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(1, 3):\n",
    "            E = np.abs(E_fields[f\"E{i}\"])**2\n",
    "            spectrum = np.abs(fftshift(fft(E * window)))\n",
    "            spectrum = 10 *np.log(spectrum)\n",
    "            plt.plot(freqs[valid], spectrum[valid], label=f\"Laser {i}\")\n",
    "        plt.xlabel(r\"$\\nu$ (GHz)\")\n",
    "        plt.ylabel(r\"$|FFT(|E(t)|^2)|$\")\n",
    "        plt.legend()\n",
    "        #plt.savefig(os.path.join(os.getcwd(), \"RHF_laser_1_laser_1_Δf_0.02_GHz.png\"))\n",
    "\n",
    "        # === Zoomed view of above ===\n",
    "        plt.figure()\n",
    "        for i in range(1, 3):\n",
    "            E = np.abs(E_fields[f\"E{i}\"])**2\n",
    "            spectrum = np.abs(fftshift(fft(E * window)))\n",
    "            spectrum = 10 * np.log(spectrum)\n",
    "            plt.plot(freqs[valid], spectrum[valid], label=f\"Laser {i}\")\n",
    "        plt.xlim([0, 20])\n",
    "        plt.xlabel(r\"$\\nu$ (GHz)\")\n",
    "        plt.ylabel(r\"$|FFT(|E(t)|^2)|$\")\n",
    "        plt.legend()\n",
    "        #plt.savefig(os.path.join(os.getcwd(), \"RHF_laser_1_laser_1_zoom_Δf_0.02_GHz.png\"))\n",
    "\n",
    "        # === FFT of complex fields (optical spectra) ===\n",
    "        plt.figure()\n",
    "        for i in range(1, 3):\n",
    "            E_complex = E_fields[f\"E{i}\"]\n",
    "            spectrum_c = np.abs(fftshift(fft(E_complex * window)))\n",
    "            db_spectrum = 20 * np.log10(spectrum_c)\n",
    "            plt.plot(freqs, db_spectrum, label=f\"Laser {i}\")\n",
    "        plt.title(rf\"{Δf}\")\n",
    "        plt.xlabel(r\"$\\nu$ (GHz)\")\n",
    "        plt.ylabel(r\"$|FFT(E_r)|$ (dB)\")\n",
    "        plt.legend()\n",
    "        #plt.savefig(os.path.join(os.getcwd(), \"optical_spectra_laser_1_laser_1_Δf_0.02_GHz.png\"))\n",
    "\n",
    "plot_function_delay_laser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befa93d",
   "metadata": {},
   "source": [
    "# Cross-correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb789d",
   "metadata": {},
   "source": [
    "## All the $C_{\\text{max}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_julia_complex(x):\n",
    "    return complex(x.replace(\"im\", \"j\").replace(\" \", \"\"))\n",
    "\n",
    "def analyze_cross_correlations():\n",
    "        \n",
    "    Δf_list = np.arange(-30, 30.1, 0.1)\n",
    "    Δf_list = np.round(Δf_list, 1)  # Round to 1 decimal place\n",
    "    for element in Δf_list:\n",
    "        if element == -0.0:\n",
    "            index = np.where(Δf_list == element)[0][0]\n",
    "            Δf_list[index] = 0.0  # Change -0.0 to 0.0\n",
    "\n",
    "    c_max_list = []\n",
    "    lag_at_cmax_list = []\n",
    "    pairs_list = []\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    h = 0.2e-12\n",
    "    Δt = 50\n",
    "    tau = 1e-8\n",
    "    lag_max_index = int(round(10*tau / (h * Δt)))  # max lag index (samples)\n",
    "\n",
    "    for Δf in Δf_list:\n",
    "        print(Δf)\n",
    "        file_path = os.path.join(rf\"/home/adam/vscode/python/Infolante/traces/results_4_lasers_new_params_larger_wait/4_lasers_simulation_Δf_{Δf}_RK4_no_noise_new_params_larger_wait.csv\")\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        t = df[\"time\"].values\n",
    "        index_steady = np.argmax(t > 1800e-9)\n",
    "\n",
    "        x1 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E1\"].values[index_steady:]]))\n",
    "        x2 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E2\"].values[index_steady:]]))\n",
    "        x3 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E3\"].values[index_steady:]]))\n",
    "        x4 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E4\"].values[index_steady:]]))\n",
    "\n",
    "        # Cross-correlation for each pair of lasers\n",
    "        lags_12, corr_vals_12 = cross_correlation(x1, x2, lag_max_index)\n",
    "        lags_13, corr_vals_13 = cross_correlation(x1, x3, lag_max_index)\n",
    "        lags_14, corr_vals_14 = cross_correlation(x1, x4, lag_max_index)\n",
    "        lags_23, corr_vals_23 = cross_correlation(x2, x3, lag_max_index)\n",
    "        lags_24, corr_vals_24 = cross_correlation(x2, x4, lag_max_index)\n",
    "        lags_34, corr_vals_34 = cross_correlation(x3, x4, lag_max_index)\n",
    "\n",
    "        # Store results for each pair\n",
    "        cross_correlation_results = {\n",
    "            \"12\": (lags_12, corr_vals_12),\n",
    "            \"13\": (lags_13, corr_vals_13),\n",
    "            \"14\": (lags_14, corr_vals_14),\n",
    "            \"23\": (lags_23, corr_vals_23),\n",
    "            \"24\": (lags_24, corr_vals_24),\n",
    "            \"34\": (lags_34, corr_vals_34),\n",
    "        }\n",
    "\n",
    "\n",
    "        for pair, (lags, corr_vals) in cross_correlation_results.items():\n",
    "            c_max = np.max(np.abs(corr_vals))\n",
    "            c_max_index = np.argmax(np.abs(corr_vals))\n",
    "            lag_at_cmax = lags[c_max_index] * 1e9 * h * Δt  # in ns\n",
    "            c_max_list.append((pair, c_max))\n",
    "            lag_at_cmax_list.append((pair, lag_at_cmax))\n",
    "\n",
    "\n",
    "    # Plot C_max vs Δf for all pairs together\n",
    "    plt.figure()\n",
    "    for pair in [\"12\", \"13\", \"14\", \"23\", \"24\", \"34\"]:\n",
    "        pair_c_max = [c_max for p, c_max in c_max_list if p == pair]\n",
    "        plt.plot(Δf_list, pair_c_max, marker='o', linewidth=1, label=f\"Pair {pair}\")\n",
    "    plt.xlabel(r\"$\\Delta f$ (GHz)\")\n",
    "    plt.ylabel(r\"$C_{\\max}$\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(current_dir, \"c_max_vs_Δf_all_pairs_RK4.png\"))\n",
    "\n",
    "    # Print lag values at which C_max occurred\n",
    "    print(\"Lag values at Cmax (in ns):\", lag_at_cmax_list)\n",
    "\n",
    "#Run analysis\n",
    "analyze_cross_correlations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370cade6",
   "metadata": {},
   "source": [
    "## Calculation Autocorrelation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9791e62",
   "metadata": {},
   "source": [
    "\"Without\" normalization (np.correlate() but we divide by the first value, which is the maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91837237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_julia_complex(x):\n",
    "    return complex(x.replace(\"im\", \"j\").replace(\" \", \"\"))\n",
    "\n",
    "def auto_corr_function():\n",
    "    Δf_list = np.arange(-22, -19, 0.1)\n",
    "    Δf_list = np.round(Δf_list, 1)  # Round to 1 decimal place\n",
    "    for element in Δf_list:\n",
    "        if element == -0.0:\n",
    "            index = np.where(Δf_list == element)[0][0]\n",
    "            Δf_list[index] = 0.0  # Change -0.0 to 0.0\n",
    "\n",
    "\n",
    "    print(Δf_list)\n",
    "    c_max_list = []\n",
    "    lag_at_cmax_list = []\n",
    "    pairs_list = []\n",
    "\n",
    "    sigma_list_0 = []\n",
    "    acf_area_list_0 = []\n",
    "\n",
    "    sigma_list_1 = []\n",
    "    acf_area_list_1 = []\n",
    "\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    h = 0.2e-12\n",
    "    Δt = 50\n",
    "    tau = 1e-8\n",
    "    lag_max_index = int(round(10*tau / (h * Δt)))  # max lag index (samples)\n",
    "\n",
    "    for Δf in Δf_list:\n",
    "        print(Δf)\n",
    "        file_path = os.path.join(rf\"/home/adam/vscode/python/Infolante/traces/results_4_lasers_new_params_larger_wait/4_lasers_simulation_Δf_{Δf}_RK4_no_noise_new_params_larger_wait.csv\")\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        t = df[\"time\"].values\n",
    "        index_steady = np.argmax(t > 19800e-9)\n",
    "\n",
    "        x1 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E1\"].values[index_steady:]]))\n",
    "        x2 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E2\"].values[index_steady:]]))\n",
    "\n",
    "        # Cross-correlation for each pair of lasers\n",
    "        lags_1, corr_vals_1 = cross_correlation(x1, x1, lag_max_index)\n",
    "        corr_vals_1 = corr_vals_1[lag_max_index - 1: 2*lag_max_index -1]\n",
    "        lags_1 = lags_1* 1e9 * h * Δt\n",
    "        lags_1 = lags_1[lag_max_index - 1: 2*lag_max_index -1]\n",
    "\n",
    "        lags_2, corr_vals_2 = cross_correlation(x2, x2, lag_max_index)\n",
    "        corr_vals_2 = corr_vals_2[lag_max_index - 1: 2*lag_max_index -1]\n",
    "        lags_2 = lags_2* 1e9 * h * Δt\n",
    "        lags_2 = lags_2[lag_max_index - 1: 2*lag_max_index -1]\n",
    "\n",
    "        area_under_acf_1 = np.trapezoid(np.abs(corr_vals_1), x =lags_1 )\n",
    "\n",
    "        area_under_acf_2 = np.trapezoid(np.abs(corr_vals_2), x =lags_2 )\n",
    "\n",
    "            #Plot C_max vs Δf for all pairs together\n",
    "        plt.figure()\n",
    "        plt.plot(lags_1, corr_vals_1, linewidth=1)\n",
    "        plt.xlabel(r\"lags(ns)\")\n",
    "        plt.ylabel(r\"$ACF_{1}$\")\n",
    "        plt.title(rf\"{Δf}, {area_under_acf_1}\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(lags_2, corr_vals_2, linewidth=1)\n",
    "        plt.xlabel(r\"lags(ns)\")\n",
    "        plt.ylabel(r\"$ACF_{2}$\")\n",
    "        plt.title(rf\"{Δf}, {area_under_acf_2}\")\n",
    "\n",
    "\n",
    "\n",
    "auto_corr_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2cab5",
   "metadata": {},
   "source": [
    "## Classification of dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_julia_complex(x):\n",
    "    return complex(x.replace(\"im\", \"j\").replace(\" \", \"\"))\n",
    "\n",
    "def analyze_cross_correlations():\n",
    "    \n",
    "    Δf_list = np.arange(-30, 30.1, 0.1)\n",
    "    Δf_list = np.round(Δf_list, 1)  # Round to 1 decimal place\n",
    "    for element in Δf_list:\n",
    "        if element == -0.0:\n",
    "            index = np.where(Δf_list == element)[0][0]\n",
    "            Δf_list[index] = 0.0  # Change -0.0 to 0.0\n",
    "\n",
    "\n",
    "    print(Δf_list)\n",
    "    c_max_list = []\n",
    "    lag_at_cmax_list = []\n",
    "    pairs_list = []\n",
    "\n",
    "    sigma_list_0 = []\n",
    "    acf_area_list_0 = []\n",
    "\n",
    "    sigma_list_1 = []\n",
    "    acf_area_list_1 = []\n",
    "\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    h = 0.2e-12\n",
    "    Δt = 50\n",
    "    tau = 1e-8\n",
    "    lag_max_index = int(round(10*tau / (h * Δt)))  # max lag index (samples)\n",
    "\n",
    "    for Δf in Δf_list:\n",
    "        print(Δf)\n",
    "        file_path = os.path.join(rf\"/home/adam/vscode/python/Infolante/traces/results_4_lasers_new_params_larger_wait/4_lasers_simulation_Δf_{Δf}_RK4_no_noise_new_params_larger_wait.csv\")\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        t = df[\"time\"].values\n",
    "        index_steady = np.argmax(t > 19800e-9)\n",
    "        index_steady_2 = np.argmax(t > 900e-9)\n",
    "\n",
    "        x1 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E1\"].values[index_steady:]]))\n",
    "        x2 = np.abs(np.array([parse_julia_complex(val) for val in df[\"E2\"].values[index_steady:]]))\n",
    "\n",
    "        x_1_lag = np.abs(np.array([parse_julia_complex(val) for val in df[\"E1\"].values[index_steady-1000:-1000]]))\n",
    "\n",
    "        #Then I should estimate the value for the delay and the embedding dimension\n",
    "\n",
    "        # Cross-correlation for each pair of lasers\n",
    "        lags_12, corr_vals_12 = cross_correlation(x1, x2, lag_max_index)\n",
    "#        lags_13, corr_vals_13 = cross_correlation(x1, x3, lag_max_index)\n",
    "#        lags_14, corr_vals_14 = cross_correlation(x1, x4, lag_max_index)\n",
    "#        lags_23, corr_vals_23 = cross_correlation(x2, x3, lag_max_index)\n",
    "#        lags_24, corr_vals_24 = cross_correlation(x2, x4, lag_max_index)\n",
    "#        lags_34, corr_vals_34 = cross_correlation(x3, x4, lag_max_index)\n",
    "\n",
    "        x_1_normalized = (x1 - np.mean(x1)) / np.std(x1)\n",
    "        x_2_normalized = (x2 - np.mean(x2)) / np.std(x2)\n",
    "\n",
    "        x_normalized = np.array((x_1_normalized,x_2_normalized))\n",
    "\n",
    "        x = np.array((x1,x2))\n",
    "        #print(\"Shape of x:\", x.shape)\n",
    "        sigma_normalized_list = np.zeros(2)\n",
    "        for i in range(len(sigma_normalized_list)):\n",
    "            sigma_normalized_list[i] = np.std(x[i,:])/np.mean(x[i,:])\n",
    "        \n",
    "        index = np.argmax(sigma_normalized_list)\n",
    "\n",
    "\n",
    "        # Cross-correlation for each pair of lasers\n",
    "        lags_1, corr_vals_1 = cross_correlation(x1, x1, lag_max_index)\n",
    "        corr_vals_1 = corr_vals_1[lag_max_index - 1: 2*lag_max_index -1]\n",
    "        lags_1 = lags_1* 1e9 * h * Δt\n",
    "        lags_1 = lags_1[lag_max_index - 1: 2*lag_max_index -1]\n",
    "\n",
    "        lags_2, corr_vals_2 = cross_correlation(x2, x2, lag_max_index)\n",
    "        corr_vals_2 = corr_vals_2[lag_max_index - 1: 2*lag_max_index -1]\n",
    "        lags_2 = lags_2* 1e9 * h * Δt\n",
    "        lags_2 = lags_2[lag_max_index - 1: 2*lag_max_index -1]\n",
    "\n",
    "        area_under_acf_1 = np.trapezoid(np.abs(corr_vals_1), x =lags_1 )\n",
    "\n",
    "        area_under_acf_2 = np.trapezoid(np.abs(corr_vals_2), x =lags_2 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sigma_list_0.append(sigma_normalized_list[0])\n",
    "        acf_area_list_0.append(area_under_acf_1)\n",
    "\n",
    "        sigma_list_1.append(sigma_normalized_list[1])\n",
    "        acf_area_list_1.append(area_under_acf_2)\n",
    "\n",
    "        # Store results for each pair\n",
    "        cross_correlation_results = {\n",
    "            \"12\": (lags_12, corr_vals_12),\n",
    "#            \"13\": (lags_13, corr_vals_13),\n",
    "#            \"14\": (lags_14, corr_vals_14),\n",
    "#            \"23\": (lags_23, corr_vals_23),\n",
    "#            \"24\": (lags_24, corr_vals_24),\n",
    "#            \"34\": (lags_34, corr_vals_34),\n",
    "        }\n",
    "\n",
    "#\n",
    "        for pair, (lags, corr_vals) in cross_correlation_results.items():\n",
    "            c_max = np.max(np.abs(corr_vals))\n",
    "            c_max_index = np.argmax(np.abs(corr_vals))\n",
    "            lag_at_cmax = lags[c_max_index] * 1e9 * h * Δt  # in ns\n",
    "            c_max_list.append((pair, c_max))\n",
    "            lag_at_cmax_list.append((pair, lag_at_cmax))\n",
    "\n",
    "    # Plot C_max vs Δf for all pairs together\n",
    "    plt.figure()\n",
    "    i = 0\n",
    "    for pair in [\"12\"]:\n",
    "        pair_c_max = [c_max for p, c_max in c_max_list if p == pair]\n",
    "        plt.plot(Δf_list, pair_c_max, linewidth=1, label=f\"Pair {pair}\", color = 'black')\n",
    "        for i in range(0,len(Δf_list)):\n",
    "            if sigma_list_0[i]<0.02 and acf_area_list_0[i]>58: #CW\n",
    "                if sigma_list_1[i]<0.02 and acf_area_list_1[i]>58:#CW\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]<58: #Chaotic\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='o', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]>58: #Oscillatory\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='^', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "                else:\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "\n",
    "\n",
    "            elif sigma_list_0[i]>0.02 and acf_area_list_0[i]<58: #Chaotic\n",
    "                if sigma_list_1[i]<0.02 and acf_area_list_1[i]>58:#CW\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'blue')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]<58: #Chaotic\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='o', linewidth=1, label=f\"Pair {pair}\", color = 'blue')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]>58: #Oscillatory\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='^', linewidth=1, label=f\"Pair {pair}\", color = 'blue')\n",
    "                else:\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'blue')\n",
    "\n",
    "\n",
    "            elif sigma_list_0[i]>0.02 and acf_area_list_0[i]>58: #oscillatory\n",
    "                if sigma_list_1[i]<0.02 and acf_area_list_1[i]>58:#CW\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'red')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]<58: #Chaotic\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='o', linewidth=1, label=f\"Pair {pair}\", color = 'red')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]>58: #Oscillatory\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='^', linewidth=1, label=f\"Pair {pair}\", color = 'red')\n",
    "                else:\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'red')\n",
    "\n",
    "            else: #dunno\n",
    "                if sigma_list_1[i]<0.02 and acf_area_list_1[i]>58:#CW\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]<58: #Chaotic\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='o', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "                elif sigma_list_1[i]>0.02 and acf_area_list_1[i]>58: #Oscillatory\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='^', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "                else:\n",
    "                    plt.scatter(Δf_list[i], pair_c_max[i], marker='s', linewidth=1, label=f\"Pair {pair}\", color = 'green')\n",
    "    \n",
    "    plt.xlabel(r\"$\\Delta f$ (GHz)\")\n",
    "    plt.ylabel(r\"$C_{\\max}$\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.savefig(os.path.join(current_dir, \"c_max_vs_Δf_RK4_network_new_again_larger_wait_increased_changed_acf.png\"))\n",
    "\n",
    "    # Print lag values at which C_max occurred\n",
    "    print(\"Lag values at Cmax (in ns):\", lag_at_cmax_list)\n",
    "\n",
    "    #Plot C_max vs Δf for all pairs together\n",
    "    plt.figure()\n",
    "    plt.plot(Δf_list, sigma_list_0, marker='o', linewidth=1)\n",
    "    plt.plot(Δf_list, sigma_list_1, marker='^', linewidth=1)\n",
    "    plt.xlabel(r\"$\\Delta f$ (GHz)\")\n",
    "    plt.ylabel(r\"$\\sigma/\\mu$\")\n",
    "    plt.savefig(os.path.join(current_dir, \"simga_mu_vs_Δf_RK4_network_new_again_larger_wait_increased_changed_acf.png\"))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(Δf_list, acf_area_list_0, marker='o', linewidth=1)\n",
    "    plt.plot(Δf_list, acf_area_list_1, marker='^', linewidth=1)\n",
    "    plt.xlabel(r\"$\\Delta f$ (GHz)\")\n",
    "    plt.ylabel(r\"$|ACF_{area}|$\")\n",
    "    plt.savefig(os.path.join(current_dir, \"acf_area_vs_Δf_RK4_network_new_again_larger_wait_increased_changed_acf.png\"))\n",
    "\n",
    "#Run analysis\n",
    "analyze_cross_correlations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
